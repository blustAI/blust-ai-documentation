"use strict";(self.webpackChunkblust_ai_documentation=self.webpackChunkblust_ai_documentation||[]).push([[956,180],{1200:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var t=n(7624),o=n(2172);const s={sidebar_position:10,sidebar_label:"Available models",title:"Available models"},a=void 0,r={id:"creating-ai-tools/available_models",title:"Available models",description:"Text generation models",source:"@site/docs/creating-ai-tools/available_models.md",sourceDirName:"creating-ai-tools",slug:"/creating-ai-tools/available_models",permalink:"/docs/creating-ai-tools/available_models",draft:!1,unlisted:!1,editUrl:"https://github.com/blustAI/blust-ai-documentation/tree/main/docs/creating-ai-tools/available_models.md",tags:[],version:"current",sidebarPosition:10,frontMatter:{sidebar_position:10,sidebar_label:"Available models",title:"Available models"},sidebar:"tutorialSidebar",previous:{title:"Voice Settings",permalink:"/docs/creating-ai-tools/voice_settings"},next:{title:"Integrating an existing AI Tool",permalink:"/docs/category/integrating-an-existing-ai-tool"}},l={},d=[{value:"Text generation models",id:"text-generation-models",level:4},{value:"Image generation models",id:"image-generation-models",level:4},{value:"Voice to text models",id:"voice-to-text-models",level:4},{value:"Text to voice models",id:"text-to-voice-models",level:4},{value:"Image recognition models",id:"image-recognition-models",level:4},{value:"Multimodal models",id:"multimodal-models",level:4},{value:"Assistants",id:"assistants",level:4}];function c(e){const i={em:"em",h4:"h4",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.M)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h4,{id:"text-generation-models",children:"Text generation models"}),"\n",(0,t.jsx)(i.p,{children:"Models in this category specialize in generating coherent and contextually relevant text across a wide variety of topics and formats. They are designed to understand and produce written language, making them ideal for applications ranging from content creation to conversation simulation."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"GPT-3.5 Turbo"}),": powered by OpenAI, is a faster variant of the original  GPT-3.5 model, designed for quick text generation with maintained quality across diverse domains."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"GPT-4"}),": The fourth iteration of the Generative Pre-trained Transformer, known for its deep comprehension and versatile text generation across numerous contexts."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"GPT-4 Turbo"}),": A turbocharged variant of GPT-4 designed for high-speed text generation, combining GPT-4's advanced understanding with improved processing speed."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Gemini Pro"}),": Gemini Pro is a scalable, general-purpose AI model developed by Google, designed to handle a variety of information. It stands out for its capability to outperform other models of similar size on research benchmarks, offering features like function calling, embeddings, semantic retrieval, custom knowledge grounding, and chat functionality."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"PaLM 2"})," ",(0,t.jsx)(i.em,{children:"(legacy)"}),":  Google's advanced large language model that contributed to generative AI capabilities across various Google technologies."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Llama-2"}),": A next-generation large language model from Meta, focused on generative AI applications."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Claude v2.1"}),": Developed by Anthropic, this advanced language model features a 200K token context window, reduced hallucination rates, and heightened accuracy. It's adept at processing extensive content for a range of applications, including business and legal document analysis\u200b"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Mistral 7B instruct"}),": A 7.3 billion parameter language model by Mistral AI, fine-tuned for conversational and question-answering tasks. Designed for real-time applications, it showcases adaptability and efficiency across a variety of tasks"]}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"image-generation-models",children:"Image generation models"}),"\n",(0,t.jsx)(i.p,{children:"These models are capable of creating detailed and diverse visual content from textual descriptions. They combine elements of creativity and artificial intelligence to produce images that match specified prompts, useful in design, art, and visual content generation."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"DALL-E 2"}),": An AI model by OpenAI capable of generating complex images from textual descriptions, known for its creativity and high fidelity outputs."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"DALL-E 3"}),": The successor to DALL-E 2, improving upon its predecessor with enhanced image quality and generation capabilities."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"OpenJorney"}),": A versatile image generation model designed to create detailed and diverse visual content based on textual prompts."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Stable Diffusion 2.1"}),": A model that excels in generating high-quality images from textual descriptions, known for its speed and versatility."]}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"voice-to-text-models",children:"Voice to text models"}),"\n",(0,t.jsx)(i.p,{children:"Voice to text models are engineered to accurately transcribe spoken language into written text. They are adept at understanding various languages, accents, and dialects, making them essential for dictation, accessibility features, and voice-controlled applications."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Whisper"}),": An advanced voice recognition model powered by OpenAI, designed to accurately transcribe spoken language into text, excelling in multiple languages and dialects."]}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"text-to-voice-models",children:"Text to voice models"}),"\n",(0,t.jsx)(i.p,{children:"Models in this category convert written text into natural-sounding spoken language. They are utilized in applications that require speech synthesis, such as virtual assistants, audiobooks, and spoken content for the visually impaired."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"TTS"}),": An OpenAI API that generates high-quality spoken audio from text, featuring six preset voices for real-time use and enhanced quality. Optimized for diverse applications, it offers streaming capabilities and supports inputs up to 4096 characters."]}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"image-recognition-models",children:"Image recognition models"}),"\n",(0,t.jsx)(i.p,{children:"These models analyze and interpret visual information from images or video streams. They can identify objects, scenes, and activities, making them useful for tasks such as image captioning, surveillance, and automated content categorization."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"GPT2 image captioning"}),": A basic AI model designed for generating textual descriptions of uploaded images, leveraging GPT-2's capabilities for visual recognition and interpretation."]}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"multimodal-models",children:"Multimodal models"}),"\n",(0,t.jsx)(i.p,{children:"Multimodal models can process and generate content that spans multiple types of input and output, such as text and images. Their versatility allows them to understand and create rich multimedia content, serving applications that require a combination of visual and textual comprehension."}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"GPT-4 Turbo Vision"}),": Combines the text generation prowess of GPT-4 Turbo with visual understanding, enabling it to process and generate content based on both text and images."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Gemini Pro Vision"}),"*: A Google-developed multimodal AI model capable of processing text, images, video, audio, and code. Optimized for a wide range of tasks"]}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"assistants",children:"Assistants"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"GPT-4 Turbo Assistant"}),": A specialized version of GPT-4 Turbo designed to act as a virtual assistant, providing high-speed responses to queries across a wide range of topics."]}),"\n"]})]})}function u(e={}){const{wrapper:i}={...(0,o.M)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},460:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var t=n(7624),o=n(2172),s=n(1200);const a={sidebar_position:2},r="Getting Started",l={id:"index",title:"Getting Started",description:"Welcome to the Blust AI Studio documentation hub. This documentation is designed for both beginners and experienced developers.",source:"@site/docs/index.mdx",sourceDirName:".",slug:"/",permalink:"/docs/",draft:!1,unlisted:!1,editUrl:"https://github.com/blustAI/blust-ai-documentation/tree/main/docs/index.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Developer Manifesto",permalink:"/docs/manifesto"},next:{title:"Creating a new AI Tool",permalink:"/docs/category/creating-a-new-ai-tool"}},d={},c=[{value:"Creating Your Account",id:"creating-your-account",level:2},{value:"Understanding Account Credits",id:"understanding-account-credits",level:2},{value:"Monthly Credit Allocation",id:"monthly-credit-allocation",level:3},{value:"Usage Pricing",id:"usage-pricing",level:3},{value:"Testing AI Tools",id:"testing-ai-tools",level:3},{value:"Adding AI Tools: Two Starting Points",id:"adding-ai-tools-two-starting-points",level:2},{value:"Option 1: Create a New AI Tool",id:"option-1-create-a-new-ai-tool",level:2},{value:"AI Role Definition",id:"ai-role-definition",level:3},{value:"Available models",id:"available-models",level:3},{value:"Option 2: Integrate an Existing AI Tool",id:"option-2-integrate-an-existing-ai-tool",level:2},{value:"Next Steps",id:"next-steps",level:2}];function u(e){const i={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.M)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h1,{id:"getting-started",children:"Getting Started"}),"\n",(0,t.jsxs)(i.p,{children:["Welcome to the ",(0,t.jsx)(i.strong,{children:"Blust AI Studio"})," documentation hub. This documentation is designed for both ",(0,t.jsx)(i.em,{children:"beginners"})," and ",(0,t.jsx)(i.em,{children:"experienced developers"}),"."]}),"\n",(0,t.jsx)(i.p,{children:"Here is how to get started."}),"\n",(0,t.jsx)(i.h2,{id:"creating-your-account",children:"Creating Your Account"}),"\n",(0,t.jsx)(i.p,{children:"To use Blust AI Studio, you'll need an account. Signing up is quick and easy:"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:["Visit the ",(0,t.jsx)(i.a,{href:"https://studio.blust.ai/register/",children:"Blust AI Studio signup page"}),"."]}),"\n",(0,t.jsx)(i.li,{children:"Enter your details to create a new account."}),"\n",(0,t.jsx)(i.li,{children:"Confirm your email address to activate your account."}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"understanding-account-credits",children:"Understanding Account Credits"}),"\n",(0,t.jsxs)(i.p,{children:["Using AI tools consumes credits from the user's account. Each action performed deducts a specific number of credits based on the ",(0,t.jsx)(i.em,{children:"tool's usage price"}),"."]}),"\n",(0,t.jsx)(i.h3,{id:"monthly-credit-allocation",children:"Monthly Credit Allocation"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Users' monthly credit limit is determined by their subscription tier."}),"\n",(0,t.jsx)(i.li,{children:"For example, the free tier includes 500 credits each month, while the 1st tier includes 9,900."}),"\n",(0,t.jsx)(i.li,{children:"Users are allowed to purchase additional credits if their balance reaches zero."}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"usage-pricing",children:"Usage Pricing"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Each AI tool on our platform has its own usage price."}),"\n",(0,t.jsx)(i.li,{children:"Prices may be structured per each 1000 tokens or per each request."}),"\n",(0,t.jsx)(i.li,{children:"The specific usage cost for each AI tool is listed in the tool's description."}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"testing-ai-tools",children:"Testing AI Tools"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Testing tools that you create in Blust AI Studio also requires credits."}),"\n",(0,t.jsx)(i.li,{children:"When testing your tool, you will be charged credits just as any user would be, even if you are the owner of the tool."}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:["Please manage your credits wisely and monitor your usage to optimize your experience on blust.AI. For more information on credit pricing and subscription tiers, visit our ",(0,t.jsx)(i.a,{href:"https://blust.ai/#blust-ai-pricing",children:"Pricing Page"}),"."]}),"\n",(0,t.jsx)(i.h2,{id:"adding-ai-tools-two-starting-points",children:"Adding AI Tools: Two Starting Points"}),"\n",(0,t.jsx)(i.p,{children:"There are two main ways to add AI tools to the blust.AI:"}),"\n",(0,t.jsx)(i.h2,{id:"option-1-create-a-new-ai-tool",children:"Option 1: Create a New AI Tool"}),"\n",(0,t.jsxs)(i.p,{children:["Blust AI Studio's no-code environment and pre-built models ",(0,t.jsx)(i.em,{children:"simplify"})," the creation of new AI tools. Here\u2019s how you can get started:"]}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.a,{href:"https://studio.blust.ai/login",children:"Log in"})," to your Blust AI Studio account and navigate to the Studio section."]}),"\n",(0,t.jsxs)(i.li,{children:["Choose an ",(0,t.jsx)(i.strong,{children:"AI model"})," from our extensive library to serve as the foundation for your AI tool."]}),"\n",(0,t.jsxs)(i.li,{children:["Define the ",(0,t.jsx)(i.strong,{children:"AI Role"})," which is a set of parameters and behaviors that describe how your AI tool functions and interacts."]}),"\n",(0,t.jsx)(i.li,{children:"Customize your AI tool or add additional capabilities to meet your specific requirements."}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"ai-role-definition",children:"AI Role Definition"}),"\n",(0,t.jsxs)(i.p,{children:["The ",(0,t.jsx)(i.code,{children:"AI Role Definition"})," is a critical step where you outline the purpose and functionality of your AI tool. This includes specifying inputs, outputs, and how the tool processes information. A well-defined ",(0,t.jsx)(i.strong,{children:"AI Role"})," ensures your tool operates effectively and meets user expectations."]}),"\n",(0,t.jsx)(i.h3,{id:"available-models",children:"Available models"}),"\n",(0,t.jsx)(s.default,{}),"\n",(0,t.jsxs)(i.p,{children:["For a detailed guide on creating AI tools, refer to our ",(0,t.jsx)(i.a,{href:"/docs/creating-ai-tools/",children:"Creating a New AI Tool"})," section."]}),"\n",(0,t.jsx)(i.h2,{id:"option-2-integrate-an-existing-ai-tool",children:"Option 2: Integrate an Existing AI Tool"}),"\n",(0,t.jsx)(i.p,{children:"If you've developed an AI Tool / App that you'd like to integrate with blust.AI, you can do so by implementing specific functionalities:"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:["Implement ",(0,t.jsx)(i.em,{children:"OAuth 2.0"})," within your App to securely handle user authentication."]}),"\n",(0,t.jsxs)(i.li,{children:["Develop functions within your backend to ",(0,t.jsx)(i.em,{children:"track"})," and ",(0,t.jsx)(i.em,{children:"report"})," usage information back to blust.AI."]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"By integrating your existing AI App, you make it available to a broader audience while maintaining control over its operation."}),"\n",(0,t.jsxs)(i.p,{children:["For step-by-step instructions on integration, visit our ",(0,t.jsx)(i.a,{href:"/docs/integrating-ai-tools/",children:"Integrating an Existing AI Tool"})," section."]}),"\n",(0,t.jsx)(i.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(i.p,{children:"After setting up your account and choosing your starting point, you're ready to dive deeper into Blust AI Studio's capabilities. Explore our documentation to learn more about creating, customizing, and monetizing your AI tools."}),"\n",(0,t.jsx)(i.p,{children:"Should you have any questions or require assistance, please reach out to our support team."}),"\n",(0,t.jsx)(i.p,{children:"Happy creating!"})]})}function h(e={}){const{wrapper:i}={...(0,o.M)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(u,{...e})}):u(e)}},2172:(e,i,n)=>{n.d(i,{I:()=>r,M:()=>a});var t=n(1504);const o={},s=t.createContext(o);function a(e){const i=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),t.createElement(s.Provider,{value:i},e.children)}}}]);